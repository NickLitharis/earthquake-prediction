{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlCe4uTxtvfN"
      },
      "source": [
        "Ο κώδικας κατασκευάζει ενα γράφημα βασισμένο στις μέσες τιμές της κλίμακας Ρίχτερ ανα χρόνο απο το 1965 μέχρι το 2021.\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Adding libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from geopy.geocoders import Nominatim\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DATA PREPROSSECING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#CLEANING DATA\n",
        "def data_cleaning():\n",
        "\n",
        "    # Load the dataset into a pandas DataFrame\n",
        "    df = pd.read_csv('earthquake_data.csv')\n",
        "\n",
        "    # Drop rows with missing values\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Remove outliers\n",
        "    df = df[df['MAGNITUDE'] > 0]\n",
        "\n",
        "data_cleaning()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "ZTIGapYjiazn",
        "outputId": "547dd2c3-6098-441a-d50e-f535472fdb96"
      },
      "outputs": [],
      "source": [
        "# DONE\n",
        "def plot_avg_magnitude_by_year(data_filepath: str):\n",
        "  # Load the data from the CSV file\n",
        "  data = pd.read_csv(data_filepath)\n",
        "\n",
        "  # Convert the datetime values to datetime objects\n",
        "  data[\"DATETIME\"] = pd.to_datetime(data[\"DATETIME\"],format=\"%m/%d/%Y %H:%M\")\n",
        "  #grouping them by year\n",
        "  grouped=data.groupby(data.DATETIME.dt.year)['MAGNITUDE'].mean()\n",
        "  \n",
        "  plt.plot(grouped)\n",
        "\n",
        "  # Add a title and axis labels to the plot\n",
        "  plt.title(\"Average Magnitude Value per Year\")\n",
        "  plt.xlabel(\"Year\")\n",
        "  plt.ylabel(\"Average Magnitude Value\")\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n",
        "    \n",
        "plot_avg_magnitude_by_year('earthquake_data.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "PhcIEaqw6X9g",
        "outputId": "505e826d-88ca-44c3-db73-d24ffe4fa82d"
      },
      "outputs": [],
      "source": [
        "#DONE\n",
        "def plot_avg_magnitude_by_decade(data_filepath: str):\n",
        "  # Load the data from the CSV file\n",
        "  data = pd.read_csv(data_filepath)\n",
        "\n",
        "  timestamp=[]\n",
        "  # Get the date and time from the first row of the 'DATETIME' column\n",
        "\n",
        "  for i in range(len(data['DATETIME'])):\n",
        "    date_time = data['DATETIME'][i]\n",
        "\n",
        "    # Split the date and time into separate parts\n",
        "    date, time = date_time.split(\" \")\n",
        "\n",
        "    # Split the date into its component parts\n",
        "    day, month, year = date.split(\"/\")\n",
        "\n",
        "\n",
        "    # Create a tuple with the date and time parts\n",
        "    result = str((int(year)//10))+'0'\n",
        "\n",
        "    # Convert the date and time tuple to Unix time\n",
        "    timestamp.append(result)\n",
        "\n",
        "  timeStamp=pd.Series(timestamp)\n",
        "  data.drop('DATETIME',axis=1)\n",
        "  data['TIME']= timeStamp.values\n",
        "  data[\"TIME\"] = pd.to_datetime(data[\"TIME\"],format=\"%Y\")\n",
        "  grouped=data.groupby(data.TIME.dt.year)['MAGNITUDE'].mean()\n",
        "\n",
        "  plt.plot(grouped)\n",
        "\n",
        "  # Add a title and axis labels to the plot\n",
        "  plt.title(\"Average Magnitude Value per Decade\")\n",
        "  plt.xlabel(\"Year\")\n",
        "  plt.ylabel(\"Average Magnitude Value\")\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n",
        "\n",
        "plot_avg_magnitude_by_decade('earthquake_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyXsgn8_kUMO"
      },
      "outputs": [],
      "source": [
        "#DONE\n",
        "\n",
        "def top_seismogenic_places(file_path,num_places):\n",
        "\n",
        "  data = pd.read_csv(file_path)\n",
        "\n",
        "  clean_data=data.drop(columns=[\"DATETIME\",\"DEPTH\",\"MAGNITUDE\"])\n",
        "  grouped=clean_data.groupby([\"LAT\",\"LONG\"])\n",
        "  top_n=grouped.size().nlargest(num_places)\n",
        "\n",
        "  #create geolocator object\n",
        "  geolocator = Nominatim(user_agent=\"earthquake\")\n",
        "\n",
        "  #for each latitude and longitude pair in top_5_seismogenic_places, get the address\n",
        "  for lat, longt in top_n.index:\n",
        "    location = geolocator.reverse(\"{}, {}\".format(lat, longt))\n",
        "    print(f'{location.address}\\n')\n",
        "  \n",
        "\n",
        "top_seismogenic_places('earthquake_data.csv', 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "LqBW2lJx3Xkp",
        "outputId": "b195d170-9c84-403c-bf86-bf58092d931c"
      },
      "outputs": [],
      "source": [
        "def plot_magnitude_perentage_data(file_path):\n",
        "  \n",
        "  data=pd.read_csv(file_path)\n",
        "  clean_data=data.drop(columns=[\"DATETIME\",\"LAT\",\"LONG\",\"DEPTH\"])\n",
        "  \n",
        "\n",
        "  clean_data[\"magnitude_group\"]=pd.cut(clean_data['MAGNITUDE'],bins=[0,3,6,8],labels=[\"micro\",\"medium\",\"large\"])\n",
        "  vals=clean_data[\"magnitude_group\"].value_counts(normalize=True)\n",
        "  \n",
        "\n",
        "  plt.bar(vals.index, vals.values)\n",
        "\n",
        "  # Add a title and axis labels to the plot\n",
        "  plt.title(\"Magnitude percentage\")\n",
        "  plt.xlabel(\"Scale\")\n",
        "  plt.ylabel(\"Percentage\")\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()\n",
        "  \n",
        "  \n",
        "plot_magnitude_perentage_data('earthquake_data.csv')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MODEL CREATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#DONE\n",
        "# Load the dataset into a pandas DataFrame\n",
        "df = pd.read_csv('earthquake_data.csv')\n",
        "\n",
        "# Convert the DATETIME column to a datetime data type\n",
        "df['DATETIME'] = pd.to_datetime(df['DATETIME'])\n",
        "\n",
        "# Set the index of the DataFrame to the DATETIME column\n",
        "df.set_index('DATETIME', inplace=True)\n",
        "\n",
        "# Select the features to use for prediction\n",
        "X = df[['LAT', 'LONG', 'DEPTH', 'MAGNITUDE']]\n",
        "\n",
        "# Select the target variable\n",
        "y = df['MAGNITUDE']\n",
        "\n",
        "# Split the data into a training set and a test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a random forest model on the training data\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the mean absolute error of the predictions\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "mse= mean_squared_error(y_test, y_pred)\n",
        "r2=r2_score(y_test, y_pred)\n",
        "\n",
        "# Print the mean absolute error\n",
        "print(\"Mean Absolute Error:\", mae)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R2 Score:\", r2)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MAKING PREDECTIONS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Testing a model\n",
        "future_data = pd.DataFrame({\n",
        "    'LAT': [35.0, -5.0, 10.0],\n",
        "    'LONG': [135.0, 160.0, 15.0],\n",
        "    'DEPTH': [10.0, 20.0, 30.0],\n",
        "    'MAGNITUDE': [7.0, 5.0, 6.0]\n",
        "})\n",
        "predictions = model.predict(future_data)\n",
        "\n",
        "# Print the predictions\n",
        "print(\"LAT |\", \"LONG |\", \"MAGNITUDE |\")\n",
        "for i in range(len(future_data)):\n",
        "    print(future_data['LAT'][i],future_data[\"LONG\"][i], predictions[i])\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8 (main, Nov  1 2022, 14:18:21) [GCC 12.2.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
